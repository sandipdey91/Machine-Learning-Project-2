{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Prediction using Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "data_file = '../data/alllines.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_data(sentence):\n",
    "    return sentence.translate(str.maketrans('','', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(dictionary, key, value):\n",
    "    if key not in dictionary:\n",
    "        dictionary[key] = []\n",
    "    dictionary[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_dict(list_data):\n",
    "    probability_dict = {}\n",
    "    given_list_length = len(list_data)\n",
    "    for item in list_data:\n",
    "        probability_dict[item] = probability_dict.get(item, 0) + 1\n",
    "    for key, value in probability_dict.items():\n",
    "        probability_dict[key] = value / given_list_length\n",
    "    return probability_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List to hold the initial states and transition states\n",
    "initial_word = {}\n",
    "second_word = {}\n",
    "transitions = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The training of the Markov model can be divided into the following stages -\n",
    "1. Tokenisation\n",
    "2. Building the state pairs\n",
    "3. Determining the probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains a Markov model based on the data in data_file\n",
    "def train_markov_model():\n",
    "    for line in open(data_file):\n",
    "        tokens = cleanup_data(line.rstrip().lower()).split()\n",
    "        tokens_length = len(tokens)\n",
    "        for i in range(tokens_length):\n",
    "            token = tokens[i]\n",
    "            if i == 0:\n",
    "                initial_word[token] = initial_word.get(token, 0) + 1\n",
    "            else:\n",
    "                prev_token = tokens[i - 1]\n",
    "                if i == tokens_length - 1:\n",
    "                    create_dict(transitions, (prev_token, token), 'END')\n",
    "                if i == 1:\n",
    "                    create_dict(second_word, prev_token, token)\n",
    "                else:\n",
    "                    prev_prev_token = tokens[i - 2]\n",
    "                    create_dict(transitions, (prev_prev_token, prev_token), token)\n",
    "    \n",
    "    # Normalize the distributions\n",
    "    initial_word_total = sum(initial_word.values())\n",
    "    for key, value in initial_word.items():\n",
    "        initial_word[key] = value / initial_word_total\n",
    "        \n",
    "    for prev_word, next_word_list in second_word.items():\n",
    "        second_word[prev_word] = probability_dict(next_word_list)\n",
    "        \n",
    "    for word_pair, next_word_list in transitions.items():\n",
    "        transitions[word_pair] = probability_dict(next_word_list)\n",
    "    \n",
    "    print('Training successful.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training successful.\n"
     ]
    }
   ],
   "source": [
    "train_markov_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generating new text from the text corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have completed the training, we will have the initial word distribution, second-word distribution and the state transition distributions. Next to generate a text corpus all we need is to write a function to sample out from the above-created distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_word(dictionary):\n",
    "    p0 = np.random.random()\n",
    "    cumulative = 0\n",
    "    for key, value in dictionary.items():\n",
    "        cumulative += value\n",
    "        if p0 < cumulative:\n",
    "            return key\n",
    "    assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing our generated text to length 15\n",
    "number_of_sentences = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate sample text\n",
    "def generate_text():\n",
    "    for i in range(number_of_sentences):\n",
    "        sentence = []\n",
    "        # Initial word\n",
    "        word0 = sample_word(initial_word)\n",
    "        sentence.append(word0)\n",
    "        # Second word\n",
    "        word1 = sample_word(second_word[word0])\n",
    "        sentence.append(word1)\n",
    "        # Subsequent words untill END\n",
    "        while True:\n",
    "            word2 = sample_word(transitions[(word0, word1)])\n",
    "            if word2 == 'END':\n",
    "                break\n",
    "            sentence.append(word2)\n",
    "            word0 = word1\n",
    "            word1 = word2\n",
    "        print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he was of more\n",
      "and fit man for brother men\n",
      "he hath had no hands to the general wreck and but that you fear\n",
      "persuade my loving proteus\n",
      "could speak for me\n",
      "you found it beggars any man\n",
      "if you be bold to ask at what i desire her name\n",
      "for here have i not cause to sigh as if the first edward the third yonder they lie the poor gentleman born\n",
      "knowing that thou shalt know i know his means are no fool\n",
      "why she hath beheld the doing\n",
      "which daily she was not inclined that way\n",
      "and prove untrue\n",
      "within this bosom\n",
      "they wound\n",
      "pray god i pray you sir\n"
     ]
    }
   ],
   "source": [
    "generate_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Performing text prediction given a sequence of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prediction(text):\n",
    "        text = cleanup_data(text.lower()).split()\n",
    "        # Initial word\n",
    "        word0 = text[0]\n",
    "        # Second word\n",
    "        if len(text) == 1:\n",
    "            word1 = sample_word(second_word[word0])\n",
    "            text.append(word1)\n",
    "        else:\n",
    "            word1 = text[1]\n",
    "        # Subsequent words untill END\n",
    "        while True:\n",
    "            word2 = max(transitions[(word0, word1)], key=transitions[(word0, word1)].get)\n",
    "            if word2 == 'END':\n",
    "                break\n",
    "            text.append(word2)\n",
    "            word0 = word1\n",
    "            word1 = word2\n",
    "        print(' '.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whose arms were moulded in their own\n"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "text_prediction(\"Whose arms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of hostile paces those opposed eyes\n"
     ]
    }
   ],
   "source": [
    "text_prediction(\"Of hostile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##https://en.wikipedia.org/wiki/Hidden_Markov_model\n",
    "##reference https://medium.com/ymedialabs-innovation/next-word-prediction-using-markov-model-570fc0475f96"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
